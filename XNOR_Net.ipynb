{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = cPickle.load(fo)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "'batches.meta',\n",
    "'data_batch_1',\n",
    "'data_batch_2',\n",
    "'data_batch_3',\n",
    "'data_batch_4',\n",
    "'data_batch_5',\n",
    "'test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "\n",
    "for each in files:  \n",
    "    path = root + each\n",
    "    b[each] = unpickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_cases_per_batch', 'label_names', 'num_vis']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['batches.meta'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'labels', 'batch_label', 'filenames']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['data_batch_1'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in files[1:-1]:\n",
    "    [x_train.append(j) for j in b[i]['data']]\n",
    "    [y_train.append(j) for j in b[i]['labels']]\n",
    "    \n",
    "train_mean = np.mean(x_train, 1)\n",
    "train_std = np.std(x_train, 1)\n",
    "\n",
    "x_train = np.array(\n",
    "    [(x_train[i]-train_mean[i])/train_std[i] for i in range(50000)])\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['batches.meta']['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs = np.array([i.reshape(3, 32, 32).transpose([1, 2, 0]) for i in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = b['test_batch']['data']\n",
    "y_test = b['test_batch']['labels']\n",
    "\n",
    "test_mean = np.mean(x_test, 1)\n",
    "test_std = np.std(x_test, 1)\n",
    "\n",
    "x_test = np.array(\n",
    "    [(x_test[i]-test_mean[i])/test_std[i] for i in range(10000)])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_rs = np.array([i.reshape(3, 32, 32).transpose([1, 2, 0]) for i in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Binary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_biases(num_filters):\n",
    "    return tf.Variable(tf.ones([num_filters]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_layer(input,\n",
    "                               num_input_channels,\n",
    "                               conv_filter_size,\n",
    "                               num_filters):  \n",
    "    \n",
    "    weights = create_weights([conv_filter_size, conv_filter_size,\n",
    "                              num_input_channels, num_filters])\n",
    "   \n",
    "    biases = create_biases(num_filters)\n",
    " \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    " \n",
    "    layer += biases\n",
    "   \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc_layer(input,          \n",
    "             num_inputs,    \n",
    "             num_outputs,\n",
    "             use_relu=True):\n",
    "    \n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    " \n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "\n",
    "filter_size_conv1 = 3\n",
    "num_filters_conv1 = 8\n",
    "\n",
    "filter_size_conv2 = 3\n",
    "num_filters_conv2 = 16\n",
    "\n",
    "filter_size_conv3 = 3\n",
    "num_filters_conv3 = 64\n",
    "\n",
    "fc_layer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = create_convolutional_layer(input=x,\n",
    "               num_input_channels=num_channels,\n",
    "               conv_filter_size=filter_size_conv1,\n",
    "               num_filters=num_filters_conv1)\n",
    "\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "               num_input_channels=num_filters_conv1,\n",
    "               conv_filter_size=filter_size_conv2,\n",
    "               num_filters=num_filters_conv2)\n",
    "\n",
    "layer_conv3= create_convolutional_layer(input=layer_conv2,\n",
    "               num_input_channels=num_filters_conv2,\n",
    "               conv_filter_size=filter_size_conv3,\n",
    "               num_filters=num_filters_conv3)\n",
    "          \n",
    "layer_flat = create_flatten_layer(layer_conv3)\n",
    "\n",
    "layer_fc1 = create_fc_layer(input=layer_flat,\n",
    "                     num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n",
    "                     num_outputs=fc_layer_size,\n",
    "                     use_relu=True)\n",
    "\n",
    "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
    "                     num_inputs=fc_layer_size,\n",
    "                     num_outputs=10,\n",
    "                     use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2,name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                    labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(y_pred_cls, tf.argmax(y_true,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 acc : 0.20000000298 error : 2032.21813965\n",
      "iteration 101 acc : 0.40000000596 error : 164.139678955\n",
      "iteration 201 acc : 0.300000011921 error : 215.76399231\n",
      "iteration 301 acc : 0.40000000596 error : 176.852157593\n",
      "iteration 401 acc : 0.300000011921 error : 185.651077271\n",
      "iteration 501 acc : 0.20000000298 error : 179.162414551\n",
      "iteration 601 acc : 0.800000011921 error : 138.081176758\n",
      "iteration 701 acc : 0.40000000596 error : 174.09387207\n",
      "iteration 801 acc : 0.699999988079 error : 144.926818848\n",
      "iteration 901 acc : 0.20000000298 error : 203.066680908\n",
      "iteration 1001 acc : 0.800000011921 error : 111.487510681\n",
      "iteration 1101 acc : 0.699999988079 error : 125.906944275\n",
      "iteration 1201 acc : 0.699999988079 error : 118.702186584\n",
      "iteration 1301 acc : 0.699999988079 error : 133.646484375\n",
      "iteration 1401 acc : 0.699999988079 error : 122.104095459\n",
      "iteration 1501 acc : 0.40000000596 error : 147.484741211\n",
      "iteration 1601 acc : 0.600000023842 error : 132.5284729\n",
      "iteration 1701 acc : 0.600000023842 error : 105.858734131\n",
      "iteration 1801 acc : 0.5 error : 131.379470825\n",
      "iteration 1901 acc : 0.40000000596 error : 114.64642334\n",
      "iteration 2001 acc : 0.800000011921 error : 145.784637451\n",
      "iteration 2101 acc : 0.800000011921 error : 115.985954285\n",
      "iteration 2201 acc : 0.5 error : 112.659385681\n",
      "iteration 2301 acc : 0.5 error : 130.808959961\n",
      "iteration 2401 acc : 0.600000023842 error : 93.2115859985\n",
      "iteration 2501 acc : 0.5 error : 126.606246948\n",
      "iteration 2601 acc : 0.600000023842 error : 95.7155838013\n",
      "iteration 2701 acc : 0.800000011921 error : 156.18536377\n",
      "iteration 2801 acc : 0.699999988079 error : 120.806335449\n",
      "iteration 2901 acc : 0.800000011921 error : 100.108337402\n",
      "iteration 3001 acc : 0.600000023842 error : 120.139572144\n",
      "iteration 3101 acc : 0.5 error : 123.151435852\n",
      "iteration 3201 acc : 0.5 error : 147.640060425\n",
      "iteration 3301 acc : 0.699999988079 error : 104.151115417\n",
      "iteration 3401 acc : 0.5 error : 97.746887207\n",
      "iteration 3501 acc : 1.0 error : 55.0021591187\n",
      "iteration 3601 acc : 0.600000023842 error : 156.526535034\n",
      "iteration 3701 acc : 0.699999988079 error : 102.720298767\n",
      "iteration 3801 acc : 0.5 error : 104.588973999\n",
      "iteration 3901 acc : 0.40000000596 error : 129.105239868\n",
      "iteration 4001 acc : 0.5 error : 108.347633362\n",
      "iteration 4101 acc : 0.699999988079 error : 95.5474700928\n",
      "iteration 4201 acc : 0.600000023842 error : 105.28237915\n",
      "iteration 4301 acc : 0.699999988079 error : 94.01978302\n",
      "iteration 4401 acc : 0.800000011921 error : 102.098754883\n",
      "iteration 4501 acc : 0.699999988079 error : 79.4592514038\n",
      "iteration 4601 acc : 0.800000011921 error : 59.9853401184\n",
      "iteration 4701 acc : 0.699999988079 error : 112.943962097\n",
      "iteration 4801 acc : 0.5 error : 169.620361328\n",
      "iteration 4901 acc : 0.699999988079 error : 111.36151886\n",
      "Model has test accuracy of 0.438800007105\n"
     ]
    }
   ],
   "source": [
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "lrmin = 0.0001\n",
    "lrmax = 0.003\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "error = []\n",
    "\n",
    "for i in range(5000):\n",
    "    \n",
    "    ll = i*batch_size\n",
    "    ul = ll + batch_size\n",
    "\n",
    "    batch_X, batch_Y = x_train_rs[ll:ul], y_train[ll:ul]\n",
    "#     batch_X, batch_Y = x_train_rs[i:i+1], y_train[i:i+1]\n",
    "    \n",
    "    \n",
    "    learning_rate = lrmin + (lrmax - lrmin) * math.exp(-i / 5000)\n",
    "#     learning_rate = 0.001\n",
    "\n",
    "    train_data = {x: batch_X, y_true: batch_Y, lr: learning_rate}\n",
    "\n",
    "    sess.run(train_step, feed_dict = train_data)\n",
    "\n",
    "    train_acc, train_entropy, train_err, pred = sess.run([accuracy, cross_entropy, cost, y_pred], feed_dict=train_data)\n",
    "    error.append(train_err)\n",
    "    \n",
    "    if not i%100:\n",
    "        print('iteration {} acc : {} error : {}'.format(i+1,train_acc, train_err))\n",
    "#         print(pred)\n",
    "\n",
    "\n",
    "test_data = {x: x_test_rs, y_true: y_test}\n",
    "test_acc, test_entropy = sess.run([accuracy,cross_entropy],feed_dict=test_data)\n",
    "\n",
    "print('Model has test accuracy of {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(x):\n",
    "    x = tf.abs(x)\n",
    "    x = tf.reduce_mean(x, axis=0)\n",
    "    x = tf.reduce_mean(x, axis=0)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def get_a_and_B(weights):\n",
    "    \n",
    "    w, h, c, n = weights.shape # 3, 3, rgb, 8\n",
    "        \n",
    "    bin_weights = tf.sign(weights)\n",
    "    \n",
    "    a = norm1(weights)\n",
    "    \n",
    "    B = tf.multiply(a, bin_weights)\n",
    "    \n",
    "    return a, B\n",
    "\n",
    "def get_K_and_H(I):\n",
    "    \n",
    "    _, w, h, c = I.shape\n",
    "    w, h = int(w), int(h)\n",
    "    \n",
    "    H = tf.sign(I)\n",
    "    \n",
    "    A = tf.reduce_sum(I, axis=3)\n",
    "    A = tf.reshape(A, [-1, w, h, 1 ])\n",
    "    k = tf.constant(1./(w*h), shape=[w,h,1,1])\n",
    "    \n",
    "    K = tf.nn.conv2d(input=A,\n",
    "                     filter=k,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "    \n",
    "    return K, H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (H*B).Ka\n",
    "\n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def conv(I, w, h, c, n): \n",
    "\n",
    "    weights = create_weights([w, h, c, n])\n",
    "\n",
    "    a, B = get_a_and_B(weights)\n",
    "    \n",
    "    K, H = get_K_and_H(I)\n",
    "    \n",
    "    #BinActiv\n",
    "    HB = tf.nn.conv2d(input=H,\n",
    "                      filter=B,\n",
    "                      strides=[1, 1, 1, 1],\n",
    "                      padding='SAME')\n",
    "    \n",
    "    #BinConv\n",
    "    HBK = tf.nn.conv2d(input=HB,\n",
    "                       filter=K,\n",
    "                       strides=[1, 1, 1, 1],\n",
    "                       padding='SAME')\n",
    "    \n",
    "    #BinPool\n",
    "    pooled = tf.nn.max_pool(value=HBK,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    \n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dimension(3), Dimension(3), Dimension(3), Dimension(8), TensorShape([Dimension(24), Dimension(3), Dimension(3), Dimension(1)]), TensorShape([Dimension(3), Dimension(1)]))\n",
      "(24, 3, 3, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1 and 32 for 'Conv2D_14' (op: 'Conv2D') with input shapes: [?,32,32,1], [?,32,32,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-894d4dfdcde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mnum_input_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0mconv_filter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_size_conv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                num_filters=num_filters_conv1)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m layer_conv2 = create_b_convolutional_layer(input=layer_conv1,\n",
      "\u001b[0;32m<ipython-input-32-9b96a95b8628>\u001b[0m in \u001b[0;36mcreate_b_convolutional_layer\u001b[0;34m(input, num_input_channels, conv_filter_size, num_filters)\u001b[0m\n\u001b[1;32m     25\u001b[0m                      \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                      padding='SAME')\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#BinPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/avinash/anaconda3/envs/datasci/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1 and 32 for 'Conv2D_14' (op: 'Conv2D') with input shapes: [?,32,32,1], [?,32,32,1]."
     ]
    }
   ],
   "source": [
    "# 3 binary conv layers, flatten layer, 2 fully connected layer\n",
    "\n",
    "l1 = conv(I, w=3, h=3,c=3, n=8)\n",
    "l2 = conv(l1, w=3, h=3, c=8, n=16)\n",
    "l3 = conv(l2, w=3, h=3, c=64, n=64)\n",
    "\n",
    "l4 = flatten(l3)\n",
    "\n",
    "l5 = fc(l4, 128)\n",
    "l6 = fc(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(l6,name=\"y_pred\")\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=l6,\n",
    "                                                    labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(y_pred_cls, tf.argmax(y_true,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = create_weights([3,3,1,2])\n",
    "# w = tf.constant(2, shape=[3,3,3,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.07360779,  0.08817574]], dtype=float32), array([[[[-0.12319851, -0.12676463]],\n",
      "\n",
      "        [[ 0.0536567 , -0.0322381 ]],\n",
      "\n",
      "        [[ 0.10264211,  0.00887774]]],\n",
      "\n",
      "\n",
      "       [[[-0.06670819, -0.07864468]],\n",
      "\n",
      "        [[ 0.10590909, -0.0497191 ]],\n",
      "\n",
      "        [[ 0.01875779, -0.03142869]]],\n",
      "\n",
      "\n",
      "       [[[-0.12760289, -0.19341318]],\n",
      "\n",
      "        [[-0.05665344, -0.09999122]],\n",
      "\n",
      "        [[ 0.00734139,  0.1725044 ]]]], dtype=float32), array([[[[-0.00906837, -0.01117756]],\n",
      "\n",
      "        [[ 0.00394955, -0.00284262]],\n",
      "\n",
      "        [[ 0.00755526,  0.0007828 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.00491024, -0.00693455]],\n",
      "\n",
      "        [[ 0.00779573, -0.00438402]],\n",
      "\n",
      "        [[ 0.00138072, -0.00277125]]],\n",
      "\n",
      "\n",
      "       [[[-0.00939257, -0.01705435]],\n",
      "\n",
      "        [[-0.00417013, -0.0088168 ]],\n",
      "\n",
      "        [[ 0.00054038,  0.0152107 ]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "bin_weights = tf.sign(w)\n",
    "a = norm1(w)\n",
    "print(sess.run([a, w, a*w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(x):\n",
    "    x = tf.abs(x)\n",
    "    x = tf.reduce_mean(x, axis=0)\n",
    "    x = tf.reduce_mean(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
